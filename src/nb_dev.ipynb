{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c028e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ad38c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'hp/hp1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cf6810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hp1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(dataset_path).split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a391f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    if isinstance(data, list):\n",
    "        return data\n",
    "    else:\n",
    "        raise ValueError(\"The JSON file does not contain a list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88869f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_list_from_json('hp/hp1_questions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e8a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list, k_list, q_list = [], [], []\n",
    "for d in data:\n",
    "    if d['output'] is None:\n",
    "        print(f\"n = {d['history_upto']}, k = {d['context']}\")\n",
    "        continue\n",
    "    n_list.append(d['history_upto'])\n",
    "    k_list.append(d['context'])\n",
    "    q_list.append(d['output'])\n",
    "    print(f\"number of questions: {len(d['output'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "237d7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['question', 'A', 'B', 'C', 'D', 'answer', 'explanation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cdc51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    a = [list(q.keys()) == keys for q in d['output']]\n",
    "    if not all(a):\n",
    "        print(\"Fail!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97de3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cis/home/adesilva/ashwin/research/RAG-exps/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42630b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9da45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ad87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0df854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,089,536 || all params: 1,544,803,840 || trainable%: 0.0705\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14165164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='Qwen/Qwen2.5-1.5B-Instruct', revision=None, inference_mode=False, r=8, target_modules={'v_proj', 'q_proj'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.1, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366b5c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
