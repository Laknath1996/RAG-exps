{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from utils import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'gutenberg/books.bin'\n",
    "auxdata_file = 'gutenberg/books_metadata.json'\n",
    "\n",
    "data = np.memmap(data_file, dtype=np.uint16, mode='r')\n",
    "auxdata = []\n",
    "with open(auxdata_file, 'r') as file:\n",
    "    for line in file:\n",
    "        auxdata.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, eval_loader):\n",
    "    model.eval()\n",
    "    total_log_likelihood = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    for batch in eval_loader:\n",
    "        X, Y = batch\n",
    "        inputs = {\n",
    "            'input_ids': X.to(1),\n",
    "            'labels': Y.to(1)\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        log_likelihood = -loss.item() * X.numel()\n",
    "        total_log_likelihood += log_likelihood\n",
    "        total_tokens += X.numel()\n",
    "\n",
    "    avg_neg_log_likelihood = -total_log_likelihood / total_tokens\n",
    "\n",
    "    try:\n",
    "        perplexity = torch.exp(torch.tensor(avg_neg_log_likelihood))\n",
    "    except OverflowError:\n",
    "        perplexity = float('inf')\n",
    "    return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel(config)\n",
    "model.to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = Library(data, auxdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "library.current = 354"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/355 [00:00<?, ?book/s]`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "step [1/9] - tr_loss: 6.2975, ppl: 617.6099:   3%|â–Ž         | 11/355 [01:10<36:53,  6.43s/book]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 47\u001b[0m tr_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m training_loss\u001b[38;5;241m.\u001b[39mappend(tr_loss)\n\u001b[1;32m     49\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] - tr_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ppl: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mppl\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "library.reset()\n",
    "\n",
    "model.to(1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "training_loss = []\n",
    "perplexity = []\n",
    "\n",
    "progress_bar = tqdm(enumerate(library), total=len(library), unit='book')\n",
    "ppl = float('inf')\n",
    "\n",
    "\n",
    "for book_id, book in progress_bar:\n",
    "    if book_id == len(library)-1:\n",
    "        break\n",
    "\n",
    "    # print(f\"Training on book {book_id}: {book['metadata']['title']}\")\n",
    "\n",
    "    train_data = book['train_data']    \n",
    "    train_loader = DataLoader(train_data, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # num_blocks = len(X)\n",
    "    # block_indices = np.arange(num_blocks)\n",
    "    # batch_indices = [block_indices[i:min(i + batch_size, num_blocks)] for i in range(0, num_blocks, batch_size)]\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for k, batch in enumerate(train_loader):\n",
    "    \n",
    "        # X_batch = torch.stack([X[i] for i in ids]).to(1)\n",
    "        # Y_batch = torch.stack([Y[i] for i in ids]).to(1)\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': x.to(1),\n",
    "            'labels': y.to(1)\n",
    "        }\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tr_loss = loss.item()\n",
    "        training_loss.append(tr_loss)\n",
    "        progress_bar.set_description(f\"step [{k + 1}/{len(train_loader)}] - tr_loss: {tr_loss:.4f}, ppl: {ppl:.4f}\")\n",
    "\n",
    "    eval_data = book['eval_data']\n",
    "    eval_loader = DataLoader(eval_data, batch_size=16, shuffle=False)\n",
    "    ppl = evaluate(model, eval_loader)\n",
    "    perplexity.append(ppl)\n",
    "    progress_bar.set_description(f\"step [{k + 1}/{len(train_loader)}] - tr_loss: {tr_loss:.4f}, ppl: {ppl:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
